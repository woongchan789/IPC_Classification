{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dataset import CustomDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "import torch.nn as nn\n",
    "from model import CustomClassifier\n",
    "from utils import calculate_multilabel_metrics\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-small and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "train = pd.read_pickle('dataset/train.pkl')\n",
    "val = pd.read_pickle('dataset/valid.pkl')\n",
    "test = pd.read_pickle('dataset/test.pkl')\n",
    "\n",
    "data = pd.concat([train, val, test], ignore_index=True)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('klue/roberta-small')\n",
    "dataset = CustomDataset(data, tokenizer)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=False)  \n",
    "\n",
    "model = CustomClassifier('klue/roberta-small', 7, device)\n",
    "model.load_state_dict(torch.load('/home/woongchan/Workspace/지재권/ipc_section_classification/results2/model_state_dict.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 147/12870 [05:13<7:32:54,  2.14s/it, Acc=0.625, F1=0.714, Prec=0.781, Rec=0.658]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/woongchan/Workspace/지재권/ipc_section_classification/inference.ipynb 셀 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22445342415f776f6f6e676368616e227d/home/woongchan/Workspace/%EC%A7%80%EC%9E%AC%EA%B6%8C/ipc_section_classification/inference.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m input_ids, attention_mask \u001b[39m=\u001b[39m batch[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(device), batch[\u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22445342415f776f6f6e676368616e227d/home/woongchan/Workspace/%EC%A7%80%EC%9E%AC%EA%B6%8C/ipc_section_classification/inference.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m section_labels \u001b[39m=\u001b[39m batch[\u001b[39m'\u001b[39m\u001b[39msection\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22445342415f776f6f6e676368616e227d/home/woongchan/Workspace/%EC%A7%80%EC%9E%AC%EA%B6%8C/ipc_section_classification/inference.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(input_ids, attention_mask)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22445342415f776f6f6e676368616e227d/home/woongchan/Workspace/%EC%A7%80%EC%9E%AC%EA%B6%8C/ipc_section_classification/inference.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m final_outputs \u001b[39m=\u001b[39m (outputs[\u001b[39m'\u001b[39m\u001b[39msection_output\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy() \u001b[39m>\u001b[39m \u001b[39m0.5\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22445342415f776f6f6e676368616e227d/home/woongchan/Workspace/%EC%A7%80%EC%9E%AC%EA%B6%8C/ipc_section_classification/inference.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m y_preds\u001b[39m.\u001b[39mappend(final_outputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Workspace/지재권/ipc_section_classification/model.py:25\u001b[0m, in \u001b[0;36mCustomClassifier.forward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, input_ids, attention_mask):\n\u001b[1;32m     24\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbert(input_ids\u001b[39m=\u001b[39minput_ids, attention_mask\u001b[39m=\u001b[39mattention_mask)\n\u001b[0;32m---> 25\u001b[0m     encoder_layer \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mTransformerEncoderLayer(d_model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mhidden_size, nhead\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m)\u001b[39m.\u001b[39;49mto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m     26\u001b[0m     transformer_encoder \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mTransformerEncoder(encoder_layer, num_layers\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     27\u001b[0m     outputs \u001b[39m=\u001b[39m transformer_encoder(outputs\u001b[39m.\u001b[39mlast_hidden_state)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:989\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    986\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m    987\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 989\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    640\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 641\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    643\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    644\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    645\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    646\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    652\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    640\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 641\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    643\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    644\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    645\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    646\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    652\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:664\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    661\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    662\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    663\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 664\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    665\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    666\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:987\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m    985\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    986\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 987\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_loss = 0\n",
    "total_section_acc = []\n",
    "total_section_precison = []\n",
    "total_section_recall = []\n",
    "total_section_f1 = []\n",
    "y_preds = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    with tqdm(dataloader, total=len(dataloader)) as t:\n",
    "        for batch in t:\n",
    "            input_ids, attention_mask = batch['input_ids'].to(device), batch['attention_mask'].to(device)\n",
    "            section_labels = batch['section'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            \n",
    "            final_outputs = (outputs['section_output'].detach().cpu().numpy() > 0.5).astype(int)\n",
    "            y_preds.append(final_outputs)\n",
    "            \n",
    "            for i in range(len(final_outputs)):\n",
    "                if final_outputs[i].sum() == 0:\n",
    "                    final_outputs[i][np.argmax(outputs['section_output'].detach().cpu().numpy()[i])] = 1\n",
    "                    \n",
    "            eval_dict = calculate_multilabel_metrics(section_labels.detach().cpu().numpy(), final_outputs)\n",
    "            total_batch_acc,total_batch_precision,total_batch_recall,total_batch_f1 = eval_dict['accuracy'], eval_dict['precision'], eval_dict['recall'], eval_dict['f1_score']\n",
    "            total_section_acc.append(total_batch_acc)\n",
    "            total_section_precison.append(total_batch_precision)\n",
    "            total_section_recall.append(total_batch_recall)\n",
    "            total_section_f1.append(total_batch_f1)\n",
    "            \n",
    "            t.set_postfix(Acc=total_batch_acc, Prec=total_batch_precision, Rec=total_batch_recall, F1=total_batch_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>section</th>\n",
       "      <th>section_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>조미료 제조시에 부산물로 얻어지는 발효 폐액과 인산암모니움염의 혼합 현탁액을 이용하...</td>\n",
       "      <td>[0, 1, 1, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>구성본문에 설명하고 도면에 예시한 바와 같이 기록매체로 형성한  정전 잠상을 토너로...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>구성불포화 폴리에스테르 수지A 진주 광택 안료B 경화 촉매C 알루미늄 알콕시드 및또...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>목적 안지오텐신 전환효소를 저해함으로써 안지오텐신 I이 안지오텐신 II로의 전환을 ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>디설파이드트리설파이드 혼합물을 함유한 개량된 하이드록실화 액체 모노머를 사용하여 자...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract                section  \\\n",
       "0  조미료 제조시에 부산물로 얻어지는 발효 폐액과 인산암모니움염의 혼합 현탁액을 이용하...  [0, 1, 1, 0, 0, 0, 0]   \n",
       "1  구성본문에 설명하고 도면에 예시한 바와 같이 기록매체로 형성한  정전 잠상을 토너로...  [0, 0, 0, 0, 0, 0, 1]   \n",
       "2  구성불포화 폴리에스테르 수지A 진주 광택 안료B 경화 촉매C 알루미늄 알콕시드 및또...  [0, 1, 0, 0, 0, 0, 0]   \n",
       "4  목적 안지오텐신 전환효소를 저해함으로써 안지오텐신 I이 안지오텐신 II로의 전환을 ...  [0, 0, 1, 0, 0, 0, 0]   \n",
       "5  디설파이드트리설파이드 혼합물을 함유한 개량된 하이드록실화 액체 모노머를 사용하여 자...  [0, 0, 1, 0, 0, 0, 0]   \n",
       "\n",
       "            section_pred  \n",
       "0  [0, 0, 1, 0, 0, 0, 0]  \n",
       "1  [0, 1, 0, 0, 0, 0, 0]  \n",
       "2  [0, 0, 1, 0, 0, 0, 0]  \n",
       "4  [0, 0, 1, 0, 0, 0, 0]  \n",
       "5  [0, 0, 1, 0, 0, 0, 0]  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds_flat = [item for sublist in y_preds for item in sublist]\n",
    "test['section_pred'] = y_preds_flat\n",
    "test.to_pickle('dataset/result.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping from index to label\n",
    "index_to_label = {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G'}\n",
    "\n",
    "# Function to convert binary list to label list\n",
    "def binary_to_labels(binary_list):\n",
    "    labels = [index_to_label[idx] for idx, value in enumerate(binary_list) if value == 1]\n",
    "    return labels\n",
    "\n",
    "# Apply the function to the 'section' and 'section_pred' columns\n",
    "data['section_labels'] = data['section'].apply(binary_to_labels)\n",
    "data['section_pred_labels'] = data['section_pred'].apply(binary_to_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['section'] = test['section'].apply(np.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "section\n",
       "1    187395\n",
       "2      3499\n",
       "3        29\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.section.apply(lambda x: x.sum()).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "section_pred\n",
       "1    190852\n",
       "2        71\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.section_pred.apply(lambda x: x.sum()).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.concatenate(test['section'].values)\n",
    "y_pred = np.concatenate(test['section_pred'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8699565494241882,\n",
       " 'precision': 0.8699565494241882,\n",
       " 'recall': 0.8699565494241882,\n",
       " 'f1_score': 0.8699565494241882}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dict = calculate_multilabel_metrics(y_true, y_pred)\n",
    "eval_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[149308,   8908],\n",
       "        [ 19478,  13229]],\n",
       "\n",
       "       [[ 98160,  39495],\n",
       "        [ 18448,  34820]],\n",
       "\n",
       "       [[154339,  10914],\n",
       "        [  8659,  17011]],\n",
       "\n",
       "       [[182246,   1176],\n",
       "        [  5135,   2366]],\n",
       "\n",
       "       [[171406,   4285],\n",
       "        [  8848,   6384]],\n",
       "\n",
       "       [[149963,  10837],\n",
       "        [ 16187,  13936]],\n",
       "\n",
       "       [[151403,   9541],\n",
       "        [ 11887,  18092]]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "# Assuming the DataFrame 'df' is already defined and contains the multi-label predictions\n",
    "# The multilabel_confusion_matrix function can be used directly on the 'section' and 'section_pred' columns\n",
    "\n",
    "# Convert lists to arrays if not already done\n",
    "test['section'] = test['section'].apply(np.array)\n",
    "test['section_pred'] = test['section_pred'].apply(np.array)\n",
    "\n",
    "# Extract true and predicted labels\n",
    "y_true = np.array(test['section'].tolist())\n",
    "y_pred = np.array(test['section_pred'].tolist())\n",
    "\n",
    "# Calculate the confusion matrix for each label\n",
    "confusion_matrices = multilabel_confusion_matrix(y_true, y_pred)\n",
    "\n",
    "confusion_matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.section_pred.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
